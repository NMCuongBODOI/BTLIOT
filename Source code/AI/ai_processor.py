

"""
Phi√™n b·∫£n s·ª≠ d·ª•ng Webcam m√°y t√≠nh
X·ª≠ l√Ω tr·ª±c ti·∫øp video stream t·ª´ camera
"""
import cv2
import numpy as np
import mediapipe as mp
import time
import requests
import threading
from collections import Counter
import base64
import math


# --- C·∫§U H√åNH ---
SERVER_URL = "http://localhost:3000/api/alert"
SAFE_DURATION = 30
CAMERA_ID = 0

class AIProcessor:
    def __init__(self):
        self.mp_holistic = mp.solutions.holistic
        self.mp_drawing = mp.solutions.drawing_utils
        self.holistic = self.mp_holistic.Holistic(
            min_detection_confidence=0.5, 
            min_tracking_confidence=0.5
        )
        self.current_status = "UNKNOWN"
        self.last_sent_time = 0
        self.send_cooldown = 2.0
        self.safe_mode_until = 0
        self.wave_counter = 0
        self.prev_wrist_x = 0
        self.prev_direction = 0
        self.WAVE_THRESHOLD = 3
        self.MIN_MOVE_DIST = 0.02

    def send_alert_thread(self, status, message, frame):
        """G·ª≠i c·∫£nh b√°o sang server Node.js"""
        try:
            _, buffer = cv2.imencode('.jpg', frame)
            jpg_as_text = base64.b64encode(buffer).decode('utf-8')
            
            payload = {
                "status": status,
                "message": message,
                "timestamp": time.time(),
                "image_base64": jpg_as_text
            }
            response = requests.post(SERVER_URL, json=payload, timeout=2)
            print(f">>> [G·ª¨I SERVER] {status}: {message}")
        except Exception as e:
            print(f"[L·ªñI] Kh√¥ng g·ª≠i ƒë∆∞·ª£c: {e}")

    def detect_wall_region(self, frame):
        """
        Ph√°t hi·ªán t∆∞·ªùng b·∫±ng C·∫°nh (Edge) thay v√¨ M√†u
        T√¨m c√°c ƒë∆∞·ªùng th·∫≥ng n·∫±m ngang d√†i nh·∫•t ·ªü n·ª≠a d∆∞·ªõi m√†n h√¨nh.
        """
        try:
            h, w = frame.shape[:2]
            
            # 1. Ch·ªâ x·ª≠ l√Ω n·ª≠a d∆∞·ªõi m√†n h√¨nh (ƒë·ªÉ tr√°nh tr·∫ßn nh√†, ƒë√®n...)
            roi_y_start = int(h * 0.3) 
            roi = frame[roi_y_start:h, 0:w]
            
            # 2. X·ª≠ l√Ω ·∫£nh: Grayscale -> Blur -> Canny
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            
            # Canny threshold: 50, 150 l√† ng∆∞·ª°ng ph·ªï bi·∫øn cho m√¥i tr∆∞·ªùng t·ª± nhi√™n
            edges = cv2.Canny(blurred, 30, 100)
            
            # 3. T√¨m ƒë∆∞·ªùng th·∫≥ng (Hough Transform)
            # minLineLength: ƒê∆∞·ªùng ph·∫£i d√†i √≠t nh·∫•t 30% chi·ªÅu r·ªông ·∫£nh m·ªõi t√≠nh l√† t∆∞·ªùng
            lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=50, 
                                    minLineLength=w//3, maxLineGap=20)
            
            if lines is None:
                return False, None
                
            wall_candidates = []
            
            for line in lines:
                x1, y1, x2, y2 = line[0]
                
                # T√≠nh ƒë·ªô nghi√™ng (ch·ªâ l·∫•y ƒë∆∞·ªùng n·∫±m ngang ho·∫∑c h∆°i nghi√™ng)
                if x2 - x1 == 0: continue # B·ªè qua ƒë∆∞·ªùng d·ªçc 90 ƒë·ªô
                slope = abs((y2 - y1) / (x2 - x1))
                
                if slope < 0.1: # Ch·ªâ l·∫•y ƒë∆∞·ªùng g·∫ßn nh∆∞ n·∫±m ngang (slope < 10%)
                    avg_y = (y1 + y2) / 2
                    length = np.sqrt((x2-x1)**2 + (y2-y1)**2)
                    wall_candidates.append((avg_y, length))
            
            if not wall_candidates:
                return False, None
                
            # 4. Logic ch·ªçn t∆∞·ªùng:
            # Ch·ªçn ƒë∆∞·ªùng d√†i nh·∫•t (ho·∫∑c b·∫°n c√≥ th·ªÉ ch·ªçn ƒë∆∞·ªùng cao nh·∫•t/th·∫•p nh·∫•t t√πy nhu c·∫ßu)
            best_wall = max(wall_candidates, key=lambda x: x[1])
            best_y_in_roi = best_wall[0]
            
            # Chuy·ªÉn ƒë·ªïi t·ªça ƒë·ªô t·ª´ ROI v·ªÅ khung h√¨nh g·ªëc
            real_wall_y = roi_y_start + best_y_in_roi
            
            # Normalize (0.0 -> 1.0)
            return True, real_wall_y / h

        except Exception as e:
            print(f"L·ªói detect wall: {e}")
            return False, None
        

    def check_pose_logic(self, landmarks, frame):
        """
        Ki·ªÉm tra logic Ng√£ v√† Tr√®o 
        S·ª≠ d·ª•ng g√≥c nghi√™ng c∆° th·ªÉ thay v√¨ t·ª∑ l·ªá khung h√¨nh.
        """
        # L·∫•y t·ªça ƒë·ªô c√°c ƒëi·ªÉm m·ªëc quan tr·ªçng (Th√¢n tr√™n)
        l_shoulder = landmarks[self.mp_holistic.PoseLandmark.LEFT_SHOULDER]
        r_shoulder = landmarks[self.mp_holistic.PoseLandmark.RIGHT_SHOULDER]
        l_hip = landmarks[self.mp_holistic.PoseLandmark.LEFT_HIP]
        r_hip = landmarks[self.mp_holistic.PoseLandmark.RIGHT_HIP]
        
        # 1. LOGIC PH√ÅT HI·ªÜN NG√É (FALL) - D·ª±a tr√™n g√≥c nghi√™ng
        # T√≠nh ƒëi·ªÉm gi·ªØa vai v√† ƒëi·ªÉm gi·ªØa h√¥ng
        mid_shoulder_x = (l_shoulder.x + r_shoulder.x) / 2
        mid_shoulder_y = (l_shoulder.y + r_shoulder.y) / 2
        
        mid_hip_x = (l_hip.x + r_hip.x) / 2
        mid_hip_y = (l_hip.y + r_hip.y) / 2
        
        # T√≠nh vector tr·ª•c c∆° th·ªÉ (t·ª´ vai xu·ªëng h√¥ng)
        dx = mid_hip_x - mid_shoulder_x
        dy = mid_hip_y - mid_shoulder_y # Y tƒÉng d·∫ßn t·ª´ tr√™n xu·ªëng d∆∞·ªõi
        
        # N·∫øu cam qu√° m·ªù, MediaPipe c√≥ th·ªÉ b·∫Øt sai khi·∫øn dy ~ 0 ho·∫∑c √¢m (ƒë·∫ßu d∆∞·ªõi ch√¢n)
        # Ch·ªâ x√©t khi ƒë·ªô tin c·∫≠y c·ªßa c√°c ƒëi·ªÉm n√†y > 0.5 (visible)
        confidence_check = (l_shoulder.visibility > 0.5 and r_shoulder.visibility > 0.5 and 
                            l_hip.visibility > 0.5 and r_hip.visibility > 0.5)
        
        if confidence_check:
            # T√≠nh g√≥c nghi√™ng so v·ªõi tr·ª•c th·∫≥ng ƒë·ª©ng (ƒë·ªô)
            # atan2 tr·∫£ v·ªÅ radian, ƒë·ªïi sang ƒë·ªô. 
            # 90 ƒë·ªô l√† ƒë·ª©ng th·∫≥ng, 0 ho·∫∑c 180 l√† n·∫±m ngang.
            angle_rad = math.atan2(dy, dx) 
            angle_deg = abs(math.degrees(angle_rad))
            
            # Chu·∫©n h√≥a g√≥c: 90 l√† ƒë·ª©ng, v·ªÅ g·∫ßn 0 ho·∫∑c 180 l√† n·∫±m
            # N·∫øu g√≥c l·ªách kh·ªèi ph∆∞∆°ng th·∫≥ng ƒë·ª©ng qu√° nhi·ªÅu -> NG√É
            # B√¨nh th∆∞·ªùng ƒë·ª©ng: g√≥c kho·∫£ng 80-100 ƒë·ªô (so v·ªõi tr·ª•c ho√†nh) ho·∫∑c -80 ƒë·∫øn -100
            # N·∫±m: g√≥c < 45 ho·∫∑c > 135
            
            is_horizontal = angle_deg < 45 or angle_deg > 135
            
            # B·ªï sung: Ki·ªÉm tra ƒë·ªô b·∫πt c·ªßa th√¢n ng∆∞·ªùi (Torso)
            # Khi n·∫±m, kho·∫£ng c√°ch d·ªçc (dy) s·∫Ω r·∫•t nh·ªè so v·ªõi kho·∫£ng c√°ch ngang vai
            shoulder_width = abs(l_shoulder.x - r_shoulder.x)
            torso_compressed = abs(dy) < shoulder_width * 0.8
            
            if is_horizontal or torso_compressed:
                return "FALL"
        else:
            # Fallback cho tr∆∞·ªùng h·ª£p cam qu√° m·ªù kh√¥ng th·∫•y h√¥ng:
            # D√πng bounding box nh∆∞ng ch·ªâ so s√°nh chi·ªÅu r·ªông vai v√† chi·ªÅu cao ƒë·∫ßu-ng·ª±c
            # (Logic c≈© nh∆∞ng g·∫Øt h∆°n)
            h_list = [lm.y for lm in landmarks]
            w_list = [lm.x for lm in landmarks]
            height = max(h_list) - min(h_list)
            width = max(w_list) - min(w_list)
            if width > height * 1.5: # TƒÉng ng∆∞·ª°ng l√™n 1.5 ƒë·ªÉ tr√°nh b√°o ·∫£o
                return "FALL"

        # 2. LOGIC PH√ÅT HI·ªÜN LEO T∆Ø·ªúNG (CLIMB) - Gi·ªØ nguy√™n logic c≈©
        has_wall, wall_y = self.detect_wall_region(frame)
        
        if has_wall and wall_y:
            upper_body_y = min(l_shoulder.y, r_shoulder.y, l_hip.y, r_hip.y)
            # N·∫øu th√¢n tr√™n cao h∆°n t∆∞·ªùng
            if upper_body_y < wall_y:
                return "CLIMB"
        
        return "NORMAL"
    
    def is_waving(self, landmarks):
        """Ki·ªÉm tra v·∫´y tay"""
        l_wrist = landmarks[self.mp_holistic.PoseLandmark.LEFT_WRIST]
        r_wrist = landmarks[self.mp_holistic.PoseLandmark.RIGHT_WRIST]
        l_shoulder = landmarks[self.mp_holistic.PoseLandmark.LEFT_SHOULDER]
        r_shoulder = landmarks[self.mp_holistic.PoseLandmark.RIGHT_SHOULDER]
        
        is_raised = l_wrist.y < l_shoulder.y or r_wrist.y < r_shoulder.y
        
        if not is_raised:
            self.wave_counter = 0
            self.prev_wrist_x = 0
            self.prev_direction = 0
            return False

        current_x = r_wrist.x if r_wrist.y < r_shoulder.y else l_wrist.x

        if self.prev_wrist_x == 0:
            self.prev_wrist_x = current_x
            return False

        dx = current_x - self.prev_wrist_x
        
        if abs(dx) > self.MIN_MOVE_DIST:
            current_dir = 1 if dx > 0 else -1
            if self.prev_direction != 0 and current_dir != self.prev_direction:
                self.wave_counter += 1
            self.prev_direction = current_dir
            self.prev_wrist_x = current_x

        if self.wave_counter >= self.WAVE_THRESHOLD:
            self.wave_counter = 0
            return True

        return False

    def check_face_status(self, face_landmarks, frame):
            """
            Ki·ªÉm tra tr·∫°ng th√°i khu√¥n m·∫∑t:
            1. B·ªè qua g√≥c nghi√™ng (Nghi√™ng c≈©ng ƒë∆∞·ª£c, mi·ªÖn l√† c√≥ m·∫∑t).
            2. Ch·ªâ t·∫≠p trung b·∫Øt KH·∫®U TRANG (ƒê·ªô m·ªãn v√πng mi·ªáng).
            Return: "OK" | "MASK"
            """
            # N·∫øu MediaPipe ƒë√£ tr·∫£ v·ªÅ face_landmarks th√¨ t·ª©c l√† KH√îNG quay l∆∞ng.
            # (V√¨ quay l∆∞ng MediaPipe s·∫Ω kh√¥ng b·∫Øt ƒë∆∞·ª£c ƒëi·ªÉm n√†o -> r∆°i v√†o case NO_FACE ·ªü ngo√†i)
            
            h, w = frame.shape[:2]
            lm = face_landmarks.landmark

            # --- KI·ªÇM TRA KH·∫®U TRANG (Heuristic) ---
            # So s√°nh ƒë·ªô "nhi·ªÖu" (variance) v√πng mi·ªáng
            # V√πng mi·ªáng th·∫≠t c√≥ m√¥i, rƒÉng -> ƒê·ªô nhi·ªÖu cao
            # Kh·∫©u trang v·∫£i/y t·∫ø -> Ph·∫≥ng, ƒë·ªô nhi·ªÖu th·∫•p
            
            try:
                # L·∫•y v√πng mi·ªáng (Landmark 13: M√¥i tr√™n, 14: M√¥i d∆∞·ªõi)
                mouth_x = int(lm[13].x * w)
                mouth_y = int(lm[13].y * h)
                
                # Crop v√πng mi·ªáng (20x20 pixel)
                crop_size = 20
                y1 = max(0, mouth_y - crop_size)
                y2 = min(h, mouth_y + crop_size)
                x1 = max(0, mouth_x - crop_size)
                x2 = min(w, mouth_x + crop_size)
                
                mouth_roi = frame[y1:y2, x1:x2]
                
                if mouth_roi.size > 0:
                    # Chuy·ªÉn ·∫£nh x√°m -> T√≠nh ƒë·ªô b√©n (Laplacian)
                    gray_roi = cv2.cvtColor(mouth_roi, cv2.COLOR_BGR2GRAY)
                    laplacian_var = cv2.Laplacian(gray_roi, cv2.CV_64F).var()
                    
                    # NG∆Ø·ª†NG (Threshold):
                    # < 50: Qu√° m·ªãn -> Kh·∫£ nƒÉng cao l√† kh·∫©u trang ho·∫∑c che m·∫∑t k√≠n
                    # > 50: C√≥ chi ti·∫øt (m√¥i, rƒÉng) -> M·∫∑t th·∫≠t
                    if laplacian_var < 50: 
                        return "MASK"
                        
            except Exception:
                pass 
                
            return "OK"

    def process_frame(self, frame):
        """X·ª≠ l√Ω 1 frame (ƒê√£ update logic check m·∫∑t)"""
        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = self.holistic.process(image)
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        
        status = "YELLOW"
        message = "Dang quet khu vuc..."
        status_color = (0, 255, 255)

        h, w = image.shape[:2]
        
        # Ph√°t hi·ªán t∆∞·ªùng (kh√¥ng log)
        has_wall, wall_y = self.detect_wall_region(frame)
        
        # V·∫º T∆Ø·ªúNG
        if has_wall and wall_y:
            wall_pixel_y = int(wall_y * h)
            cv2.line(image, (0, wall_pixel_y), (w, wall_pixel_y), (0, 255, 0), 3)
            cv2.putText(image, f"WALL", (10, wall_pixel_y - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

        if results.pose_landmarks:
            # V·∫Ω skeleton
            self.mp_drawing.draw_landmarks(
                image, results.pose_landmarks, self.mp_holistic.POSE_CONNECTIONS)
            
            landmarks = results.pose_landmarks.landmark
            pose_status = self.check_pose_logic(landmarks, frame)
            
            face_status = "UNKNOWN"
            if results.face_landmarks:
                # C√≥ landmark -> M·∫∑t ƒëang nh√¨n (d√π nghi√™ng hay th·∫≥ng)
                face_status = self.check_face_status(results.face_landmarks, frame)
            else:
                # Kh√¥ng c√≥ landmark -> Quay l∆∞ng ho·∫∑c Kh√¥ng c√≥ m·∫∑t
                face_status = "NO_FACE"

            # --- T·ªîNG H·ª¢P C·∫¢NH B√ÅO ---
            if pose_status == "FALL":
                status = "RED"
                message = "NGUY HIEM: Phat hien nguoi NGA!"
                status_color = (0, 0, 255)
            elif pose_status == "CLIMB":
                status = "RED"
                message = "NGUY HIEM: Phat hien LEO TUONG!"
                status_color = (0, 0, 255)
            
            # Logic check m·∫∑t:
            elif face_status != "OK":
                status = "RED"
                status_color = (0, 0, 255)
                
                if face_status == "NO_FACE":
                    # ƒê√¢y l√† tr∆∞·ªùng h·ª£p: Quay ƒë·∫ßu v·ªÅ cam (m·∫•t landmark) ho·∫∑c che k√≠n m√≠t
                    message = "CANH BAO: Khong thay mat / Quay lung"
                elif face_status == "MASK":
                    # ƒê√¢y l√† tr∆∞·ªùng h·ª£p: C√≥ m·∫∑t nh∆∞ng v√πng m·ªìm qu√° ph·∫≥ng
                    message = "CANH BAO: Phat hien KHAU TRANG!"
            
            else:
                # M·∫∑t OK (c√≥ chi ti·∫øt mi·ªáng) + D√°ng OK -> Check Safe Mode
                if time.time() < self.safe_mode_until:
                    status = "GREEN"
                    remaining_time = int(self.safe_mode_until - time.time())
                    message = f"XAC NHAN: An toan ({remaining_time}s)"
                    status_color = (0, 255, 0)
                else:
                    if self.is_waving(landmarks):
                        self.safe_mode_until = time.time() + SAFE_DURATION
                        message = "DA KICH HOAT CHE DO AN TOAN!"
                        status_color = (0, 255, 0)
                        print(message)
                    else:
                        status = "YELLOW"
                        message = "Phat hien nguoi - Chua xac minh"
                        status_color = (0, 255, 255)
        else:
            status = "NORMAL"
            message = "Khong co nguoi"
            status_color = (128, 128, 128)

        # G·ª≠i c·∫£nh b√°o
        if status != self.current_status:
            if time.time() - self.last_sent_time > self.send_cooldown:
                t = threading.Thread(target=self.send_alert_thread, args=(status, message, image))
                t.start()
                self.last_sent_time = time.time()
            self.current_status = status

        # V·∫Ω status
        cv2.rectangle(image, (10, 10), (630, 80), (0, 0, 0), -1)
        cv2.putText(image, f"Status: {status}", (20, 40), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, status_color, 2)
        cv2.putText(image, message, (20, 65), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

        return image

def main():
    print("\nü§ñ AI Surveillance System - Webcam Version")
    print("üìπ Kh·ªüi ƒë·ªông camera...")
    
    cap = cv2.VideoCapture(CAMERA_ID)
    
    if not cap.isOpened():
        print("‚ùå Kh√¥ng th·ªÉ m·ªü camera!")
        return
    
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    
    processor = AIProcessor()
    print("‚úÖ H·ªá th·ªëng s·∫µn s√†ng!")
    print("üìã H∆∞·ªõng d·∫´n:")
    print("   - V·∫´y tay ƒë·ªÉ k√≠ch ho·∫°t ch·∫ø ƒë·ªô an to√†n")
    print("   - Nh·∫•n 'q' ƒë·ªÉ tho√°t")
    print("-" * 50)
    
    fps_time = time.time()
    fps_counter = 0
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                print("‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c frame!")
                break
            
            processed_frame = processor.process_frame(frame)
            
            # T√≠nh FPS
            fps_counter += 1
            if time.time() - fps_time > 1.0:
                fps = fps_counter / (time.time() - fps_time)
                fps_counter = 0
                fps_time = time.time()
                cv2.putText(processed_frame, f"FPS: {fps:.1f}", (540, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            cv2.imshow('AI Surveillance - Webcam', processed_frame)
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                print("\nüëã ƒêang tho√°t...")
                break
                
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è ƒê√£ d·ª´ng b·ªüi ng∆∞·ªùi d√πng")
    finally:
        cap.release()
        cv2.destroyAllWindows()
        print("‚úÖ ƒê√£ ƒë√≥ng camera v√† c·ª≠a s·ªï")

if __name__ == '__main__':
    main()

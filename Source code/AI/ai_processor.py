"""
Flask API nh·∫≠n ·∫£nh t·ª´ Node.js v√† x·ª≠ l√Ω b·∫±ng AI
Ch·∫°y tr√™n port 5001 (kh√°c v·ªõi webcam_stream.py port 5000)
"""
from flask import Flask, request, jsonify
import cv2
import numpy as np
import base64
import mediapipe as mp
import time
import requests
import threading
from collections import Counter

app = Flask(__name__)

# --- C·∫§U H√åNH ---
SERVER_URL = "http://localhost:3000/api/alert"
WAVE_TRIGGER_FRAMES = 30
SAFE_DURATION = 30

class AIProcessor:
    def __init__(self):
        self.mp_holistic = mp.solutions.holistic
        self.holistic = self.mp_holistic.Holistic(
            min_detection_confidence=0.5, 
            min_tracking_confidence=0.5
        )
        self.current_status = "UNKNOWN"
        self.last_sent_time = 0
        self.send_cooldown = 2.0
        self.safe_mode_until = 0
        self.wave_counter = 0
        self.prev_wrist_x = 0
        self.prev_direction = 0
        self.WAVE_THRESHOLD = 3
        self.MIN_MOVE_DIST = 0.02

    def send_alert_thread(self, status, message, frame):
        """G·ª≠i c·∫£nh b√°o sang server Node.js"""
        try:
            _, buffer = cv2.imencode('.jpg', frame)
            jpg_as_text = base64.b64encode(buffer).decode('utf-8')
            
            payload = {
                "status": status,
                "message": message,
                "timestamp": time.time(),
                "image_base64": jpg_as_text
            }
            response = requests.post(SERVER_URL, json=payload, timeout=2)
            print(f">>> [G·ª¨I SERVER] {status}: {message}")
        except Exception as e:
            print(f"[L·ªñI] Kh√¥ng g·ª≠i ƒë∆∞·ª£c: {e}")

    def detect_wall_region(self, frame):
        """
        Ph√°t hi·ªán t∆∞·ªùng b·∫±ng C·∫°nh (Edge) thay v√¨ M√†u
        T√¨m c√°c ƒë∆∞·ªùng th·∫≥ng n·∫±m ngang d√†i nh·∫•t ·ªü n·ª≠a d∆∞·ªõi m√†n h√¨nh.
        (Logic t·ª´ temp2.py)
        """
        try:
            h, w = frame.shape[:2]
            
            # 1. Ch·ªâ x·ª≠ l√Ω n·ª≠a d∆∞·ªõi m√†n h√¨nh (ƒë·ªÉ tr√°nh tr·∫ßn nh√†, ƒë√®n...)
            roi_y_start = int(h * 0.3) 
            roi = frame[roi_y_start:h, 0:w]
            
            # 2. X·ª≠ l√Ω ·∫£nh: Grayscale -> Blur -> Canny
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            
            # Canny threshold: 50, 150 l√† ng∆∞·ª°ng ph·ªï bi·∫øn cho m√¥i tr∆∞·ªùng t·ª± nhi√™n
            edges = cv2.Canny(blurred, 30, 100)
            
            # 3. T√¨m ƒë∆∞·ªùng th·∫≥ng (Hough Transform)
            # minLineLength: ƒê∆∞·ªùng ph·∫£i d√†i √≠t nh·∫•t 30% chi·ªÅu r·ªông ·∫£nh m·ªõi t√≠nh l√† t∆∞·ªùng
            lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=50, 
                                    minLineLength=w//3, maxLineGap=20)
            
            if lines is None:
                return False, None
                
            wall_candidates = []
            
            for line in lines:
                x1, y1, x2, y2 = line[0]
                
                # T√≠nh ƒë·ªô nghi√™ng (ch·ªâ l·∫•y ƒë∆∞·ªùng n·∫±m ngang ho·∫∑c h∆°i nghi√™ng)
                if x2 - x1 == 0: continue # B·ªè qua ƒë∆∞·ªùng d·ªçc 90 ƒë·ªô
                slope = abs((y2 - y1) / (x2 - x1))
                
                if slope < 0.1: # Ch·ªâ l·∫•y ƒë∆∞·ªùng g·∫ßn nh∆∞ n·∫±m ngang (slope < 10%)
                    avg_y = (y1 + y2) / 2
                    length = np.sqrt((x2-x1)**2 + (y2-y1)**2)
                    wall_candidates.append((avg_y, length))
            
            if not wall_candidates:
                return False, None
                
            # 4. Logic ch·ªçn t∆∞·ªùng:
            # Ch·ªçn ƒë∆∞·ªùng d√†i nh·∫•t (ho·∫∑c b·∫°n c√≥ th·ªÉ ch·ªçn ƒë∆∞·ªùng cao nh·∫•t/th·∫•p nh·∫•t t√πy nhu c·∫ßu)
            best_wall = max(wall_candidates, key=lambda x: x[1])
            best_y_in_roi = best_wall[0]
            
            # Chuy·ªÉn ƒë·ªïi t·ªça ƒë·ªô t·ª´ ROI v·ªÅ khung h√¨nh g·ªëc
            real_wall_y = roi_y_start + best_y_in_roi
            
            # Normalize (0.0 -> 1.0)
            return True, real_wall_y / h

        except Exception as e:
            print(f"L·ªói detect wall: {e}")
            return False, None

    def check_pose_logic(self, landmarks, frame):
        """Ki·ªÉm tra logic Ng√£ v√† Tr√®o (Logic t·ª´ temp2.py)"""
        h_list = [lm.y for lm in landmarks]
        w_list = [lm.x for lm in landmarks]
        
        height = max(h_list) - min(h_list)
        width = max(w_list) - min(w_list)
        
        # Ph√°t hi·ªán ng√£
        if width > height * 1.2:
            return "FALL"
        
        # Ph√°t hi·ªán leo t∆∞·ªùng
        has_wall, wall_y = self.detect_wall_region(frame)
        
        if has_wall and wall_y:
            l_hip = landmarks[self.mp_holistic.PoseLandmark.LEFT_HIP].y
            r_hip = landmarks[self.mp_holistic.PoseLandmark.RIGHT_HIP].y
            l_shoulder = landmarks[self.mp_holistic.PoseLandmark.LEFT_SHOULDER].y
            r_shoulder = landmarks[self.mp_holistic.PoseLandmark.RIGHT_SHOULDER].y
            
            upper_body_y = min(l_shoulder, r_shoulder, l_hip, r_hip)
            
            # N·∫øu th√¢n tr√™n cao h∆°n t∆∞·ªùng = ƒëang leo
            if upper_body_y < wall_y:
                return "CLIMB"
        
        return "NORMAL"

    def is_waving(self, landmarks):
        """Ki·ªÉm tra v·∫´y tay"""
        l_wrist = landmarks[self.mp_holistic.PoseLandmark.LEFT_WRIST]
        r_wrist = landmarks[self.mp_holistic.PoseLandmark.RIGHT_WRIST]
        l_shoulder = landmarks[self.mp_holistic.PoseLandmark.LEFT_SHOULDER]
        r_shoulder = landmarks[self.mp_holistic.PoseLandmark.RIGHT_SHOULDER]
        
        is_raised = l_wrist.y < l_shoulder.y or r_wrist.y < r_shoulder.y
        
        if not is_raised:
            self.wave_counter = 0
            self.prev_wrist_x = 0
            self.prev_direction = 0
            return False

        current_x = r_wrist.x if r_wrist.y < r_shoulder.y else l_wrist.x

        if self.prev_wrist_x == 0:
            self.prev_wrist_x = current_x
            return False

        dx = current_x - self.prev_wrist_x
        
        if abs(dx) > self.MIN_MOVE_DIST:
            current_dir = 1 if dx > 0 else -1
            if self.prev_direction != 0 and current_dir != self.prev_direction:
                self.wave_counter += 1
                print(f"üëã Detect Wave: {self.wave_counter}/{self.WAVE_THRESHOLD}")
            self.prev_direction = current_dir
            self.prev_wrist_x = current_x

        if self.wave_counter >= self.WAVE_THRESHOLD:
            self.wave_counter = 0
            return True

        return False

    def process_frame(self, frame):
        """X·ª≠ l√Ω 1 frame t·ª´ ESP32-CAM"""
        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = self.holistic.process(image)
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        
        status = "YELLOW"
        message = "Dang quet khu vuc..."

        if results.pose_landmarks:
            landmarks = results.pose_landmarks.landmark
            pose_status = self.check_pose_logic(landmarks, frame)  # Truy·ªÅn th√™m frame
            has_face = results.face_landmarks is not None
            
            if pose_status == "FALL":
                status = "RED"
                message = "NGUY HIEM: Phat hien nguoi NGA!"
            elif pose_status == "CLIMB":
                status = "RED"
                message = "NGUY HIEM: Phat hien LEO TUONG!"
            elif not has_face:
                status = "RED"
                message = "CANH BAO: Nguoi giau mat / Quay lung"
            else:
                if time.time() < self.safe_mode_until:
                    status = "GREEN"
                    remaining_time = int(self.safe_mode_until - time.time())
                    message = f"XAC NHAN: An toan ({remaining_time}s)"
                else:
                    if self.is_waving(landmarks):
                        self.safe_mode_until = time.time() + SAFE_DURATION
                        message = "DA KICH HOAT CHE DO AN TOAN!"
                        print(message)
                    else:
                        status = "YELLOW"
                        message = "Phat hien nguoi - Chua xac minh"
        else:
            status = "NORMAL"
            message = "Khong co nguoi"

        # G·ª≠i c·∫£nh b√°o n·∫øu tr·∫°ng th√°i thay ƒë·ªïi
        if status != self.current_status:
            if time.time() - self.last_sent_time > self.send_cooldown:
                t = threading.Thread(target=self.send_alert_thread, args=(status, message, image))
                t.start()
                self.last_sent_time = time.time()
            self.current_status = status

        return {"status": status, "message": message}

# Kh·ªüi t·∫°o AI processor
processor = AIProcessor()

@app.route('/process_frame', methods=['POST'])
def process_frame():
    """Nh·∫≠n ·∫£nh base64 t·ª´ Node.js v√† x·ª≠ l√Ω"""
    try:
        data = request.json
        image_base64 = data.get('image')
        
        # Decode base64 ‚Üí numpy array
        img_bytes = base64.b64decode(image_base64)
        nparr = np.frombuffer(img_bytes, np.uint8)
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        if frame is None:
            return jsonify({"error": "Invalid image"}), 400
        
        # X·ª≠ l√Ω AI
        result = processor.process_frame(frame)
        
        return jsonify(result), 200
        
    except Exception as e:
        print(f"[ERROR] {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/health', methods=['GET'])
def health():
    return jsonify({"status": "ok", "service": "AI Processor"}), 200

if __name__ == '__main__':
    print("\nü§ñ AI Processor Service")
    print("üì° Listening on http://localhost:5001")
    print("üì• Waiting for frames from Node.js...")
    app.run(host='0.0.0.0', port=5001, debug=False)